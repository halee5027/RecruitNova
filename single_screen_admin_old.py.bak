import streamlit as st
import pandas as pd
import plotly.express as px
import os
import hashlib
from datetime import datetime as dtime
import time
from io import BytesIO
import tempfile
import random
from resume_fetcher import ResumeFetcher, FETCHED_RESUMES_DIR
from resume_ui import show_fetch_and_screen_page


# YOUR ORIGINAL IMPORTS
from utils.extract import extract_text_from_file, extract_skills, match_job_skills
from utils.experience import estimate_experience_years, experience_percentage, classify_experience_level
from utils.ranking import calculate_final_score
from utils.analyzer import analyze_resume
from utils.performance_predictor import predict_performance



# NEW FEATURES
from ui_components import stat_boxes, metric_card, show_header_with_user

REPORTS_DIR = "admin_reports"
RESUMES_DIR = "stored_resumes"

os.makedirs(REPORTS_DIR, exist_ok=True)
os.makedirs(RESUMES_DIR, exist_ok=True)

# Initialize session state for downloads
if "bulk_download_data" not in st.session_state:
    st.session_state.bulk_download_data = None
if "bulk_download_filename" not in st.session_state:
    st.session_state.bulk_download_filename = None
if "auto_download_data" not in st.session_state:
    st.session_state.auto_download_data = None
if "auto_download_filename" not in st.session_state:
    st.session_state.auto_download_filename = None

# ==================== ATS SCORE CALCULATION ====================
def calculate_ats_score(resume_text, job_desc):
    """
    Calculate ATS (Applicant Tracking System) score
    ATS evaluates resume format, keywords, and structure
    """
    ats_score = 0
    ats_details = {
        "format_score": 0,
        "keyword_score": 0,
        "structure_score": 0,
        "content_score": 0,
        "issues": []
    }
    
    # 1. FORMAT SCORE (25 points max)
    format_score = 0
    if len(resume_text) < 500:
        ats_details["issues"].append("‚ùóÔ∏è Resume too short (ATS may not parse)")
    else:
        format_score += 10
    
    if '\n' in resume_text and len(resume_text.split('\n')) > 20:
        format_score += 10
    else:
        ats_details["issues"].append("‚ùóÔ∏è Poor formatting/structure")
    
    if not any(char in resume_text for char in ['@', '.']):
        ats_details["issues"].append("‚ùóÔ∏è No contact information found")
    else:
        format_score += 5
    
    ats_details["format_score"] = format_score
    ats_score += format_score
    
    # 2. KEYWORD SCORE (35 points max)
    keyword_score = 0
    resume_lower = resume_text.lower()
    jd_lower = job_desc.lower()
    
    # Extract keywords from JD
    jd_keywords = set(jd_lower.split())
    jd_keywords = {kw for kw in jd_keywords if len(kw) > 3}  # Only words > 3 chars
    
    # Count matching keywords
    matching_keywords = 0
    for keyword in jd_keywords:
        if keyword in resume_lower:
            matching_keywords += 1
    
    if jd_keywords:
        keyword_match_percent = (matching_keywords / len(jd_keywords)) * 100
        keyword_score = min(35, int(keyword_match_percent * 0.35))  # Max 35 points
    else:
        keyword_score = 20
    
    if matching_keywords == 0:
        ats_details["issues"].append("‚ùóÔ∏è Very few keywords match job description")
    
    ats_details["keyword_score"] = keyword_score
    ats_score += keyword_score
    
    # 3. STRUCTURE SCORE (20 points max)
    structure_score = 0
    sections = ["experience", "education", "skill", "project", "summary"]
    found_sections = sum(1 for section in sections if section in resume_lower)
    
    structure_score = min(20, found_sections * 4)
    
    if found_sections < 2:
        ats_details["issues"].append("√¢≈° √Ø¬∏¬è Missing important sections (Experience/Education)")
    
    ats_details["structure_score"] = structure_score
    ats_score += structure_score
    
    # 4. CONTENT SCORE (20 points max)
    content_score = 0
    
    # Check for numbers/metrics (indicates quantified achievements)
    if any(char.isdigit() for char in resume_text):
        content_score += 7
    else:
        ats_details["issues"].append("√¢≈° √Ø¬∏¬è No quantified achievements/metrics")
    
    # Check for action verbs
    action_verbs = ["developed", "managed", "led", "created", "implemented", "designed", 
                    "achieved", "increased", "improved", "reduced", "built"]
    action_count = sum(1 for verb in action_verbs if verb in resume_lower)
    content_score += min(8, action_count)
    
    # Check for relevant experience keywords
    if "year" in resume_lower or "month" in resume_lower:
        content_score += 5
    else:
        ats_details["issues"].append("‚ùóÔ∏è Duration of experience not clearly mentioned")
    
    ats_details["content_score"] = content_score
    ats_score += content_score
    
    # Final ATS Score (0-100)
    ats_score = min(100, ats_score)
    
    # Determine ATS Rating
    if ats_score >= 80:
        ats_rating = "üëè Excellent"
    elif ats_score >= 60:
        ats_rating = "üëå Good"
    elif ats_score >= 40:
        ats_rating = "üëçüèª  Fair"
    else:
        ats_rating = "üëéüèª Poor"
    
    return {
        "ats_score": round(ats_score, 2),
        "ats_rating": ats_rating,
        "format_score": format_score,
        "keyword_score": keyword_score,
        "structure_score": structure_score,
        "content_score": content_score,
        "issues": ats_details["issues"]
    }


def get_file_hash(file_content):
    """Get hash of file for duplicate detection"""
    return hashlib.md5(file_content).hexdigest()

def detect_duplicates(resumes_data):
    """Detect duplicate resumes"""
    hashes = {}
    duplicates = []
    
    for idx, resume in enumerate(resumes_data):
        file_hash = resume.get("hash")
        if file_hash in hashes:
            duplicates.append((idx, hashes[file_hash]))
            resume["is_duplicate"] = True
        else:
            hashes[file_hash] = idx
            resume["is_duplicate"] = False
    
    return resumes_data

def extract_contact_from_resume(resume_text):
    """Extract email and contact from resume"""
    import re
    
    email_pattern = r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}'
    phone_pattern = r'(\+\d{1,3}[-.\\s]?)?\d{3}[-.\\s]?\d{3}[-.\\s]?\d{4}'
    
    email = re.search(email_pattern, resume_text)
    phone = re.search(phone_pattern, resume_text)
    
    return {
        "email": email.group(0) if email else "Not provided",
        "contact": phone.group(0) if phone else "Not provided"
    }

def screen_single_resume(job_desc, resume_file):
    """Screen a single resume against JD - USES YOUR ORIGINAL LOGIC + ATS"""
    try:
        resume_text = extract_text_from_file(resume_file)
        skills = extract_skills(resume_text)
        exp_years = estimate_experience_years(resume_text)
        skill_match = match_job_skills(skills, job_desc)
        exp_match = experience_percentage(exp_years, 3)
        final_score = calculate_final_score(skill_match, exp_match)
        exp_label = classify_experience_level(exp_years)
        analysis = analyze_resume(resume_text, job_desc)
        contact_info = extract_contact_from_resume(resume_text)
        
        # NEW: Calculate ATS Score
        ats_data = calculate_ats_score(resume_text, job_desc)
        
        return {
            "status": "success",
            "text": resume_text,
            "skills": skills,
            "exp_years": exp_years,
            "skill_match": skill_match,
            "exp_match": exp_match,
            "final_score": final_score,
            "exp_label": exp_label,
            "analysis": analysis,
            "email": contact_info["email"],
            "contact": contact_info["contact"],
            "ats_score": ats_data["ats_score"],
            "ats_rating": ats_data["ats_rating"],
            "ats_details": ats_data
        }
    
    except Exception as e:
        return {"status": "error", "message": str(e)}

def screen_bulk_resumes(job_desc, resume_files):
    """Screen multiple resumes and return ranked results"""
    results = []
    
    for resume_file in resume_files:
        result = screen_single_resume(job_desc, resume_file)
        
        if result["status"] == "success":
            score = result["final_score"]
            
            if score >= 75:
                fit = "Strongly Fit"
            elif score >= 50:
                fit = "Mid Fit"
            else:
                fit = "Low Fit"
            
            file_content = resume_file.read()
            file_hash = get_file_hash(file_content)
            resume_file.seek(0)
            
            results.append({
                "candidate_name": resume_file.name.replace('.pdf', '').replace('.docx', '').replace('.txt', ''),
                "email": result.get("email", "Not provided"),
                "contact": result.get("contact", "Not provided"),
                "skills": ", ".join(result["skills"][:5]),
                "experience_level": result["exp_label"],
                "skill_match": round(result["skill_match"], 2),
                "exp_match": round(result["exp_match"], 2),
                "overall_score": round(result["final_score"], 2),
                "ats_score": result.get("ats_score", 0),
                "ats_rating": result.get("ats_rating", "N/A"),
                "fit": fit,
                "hash": file_hash,
                "resume_path": None,
                "file_content": file_content,
                "original_filename": resume_file.name,
                "ats_details": result.get("ats_details", {})
            })
    
    results.sort(key=lambda x: x["overall_score"], reverse=True)
    return detect_duplicates(results)

def screen_with_jd(job_desc, resume_folder_path=None):
    """Auto-screen all resumes against JD without manual upload"""
    results = []
    
    if not resume_folder_path or not os.path.exists(resume_folder_path):
        return {"status": "error", "message": "Invalid folder path"}
    
    supported_formats = ('.pdf', '.docx', '.txt')
    
    for filename in os.listdir(resume_folder_path):
        if filename.lower().endswith(supported_formats):
            filepath = os.path.join(resume_folder_path, filename)
            
            try:
                with open(filepath, 'rb') as f:
                    resume_text = extract_text_from_file(f)
                
                skills = extract_skills(resume_text)
                exp_years = estimate_experience_years(resume_text)
                skill_match = match_job_skills(skills, job_desc)
                exp_match = experience_percentage(exp_years, 3)
                final_score = calculate_final_score(skill_match, exp_match)
                exp_label = classify_experience_level(exp_years)
                contact_info = extract_contact_from_resume(resume_text)
                
                # NEW: Calculate ATS Score
                ats_data = calculate_ats_score(resume_text, job_desc)
                
                if final_score >= 75:
                    fit = "Strongly Fit"
                elif final_score >= 50:
                    fit = "Mid Fit"
                else:
                    fit = "Low Fit"
                
                file_content = open(filepath, 'rb').read()
                file_hash = get_file_hash(file_content)
                
                results.append({
                    "candidate_name": filename.replace('.pdf', '').replace('.docx', '').replace('.txt', ''),
                    "email": contact_info.get("email", "Not provided"),
                    "contact": contact_info.get("contact", "Not provided"),
                    "skills": ", ".join(skills[:5]) if skills else "None",
                    "experience_level": exp_label,
                    "skill_match": round(skill_match, 2),
                    "exp_match": round(exp_match, 2),
                    "overall_score": round(final_score, 2),
                    "ats_score": ats_data["ats_score"],
                    "ats_rating": ats_data["ats_rating"],
                    "fit": fit,
                    "hash": file_hash,
                    "resume_path": filepath,
                    "file_content": file_content,
                    "original_filename": filename,
                    "ats_details": ats_data
                })
            
            except Exception as e:
                st.warning(f"Error processing {filename}: {str(e)}")
    
    results.sort(key=lambda x: x["overall_score"], reverse=True)
    return {"status": "success", "results": detect_duplicates(results)}

def save_bulk_report(results, job_desc, mode="bulk"):
    """Save bulk screening results to Excel - ENHANCED with validation"""
    try:
        # Prepare data
        export_results = []
        
        for r in results:
            export_results.append({
                "Rank": results.index(r) + 1,
                "Candidate Name": r.get("candidate_name", ""),
                "Email": r.get("email", ""),
                "Contact": r.get("contact", ""),
                "Experience Level": r.get("experience_level", ""),
                "Skill Match %": r.get("skill_match", 0),
                "Experience Match %": r.get("exp_match", 0),
                "Overall Score": r.get("overall_score", 0),
                "ATS Score": r.get("ats_score", 0),
                "ATS Rating": r.get("ats_rating", ""),
                "Fit Level": r.get("fit", ""),
                "Is Duplicate": "Yes" if r.get("is_duplicate") else "No"
            })
        
        df = pd.DataFrame(export_results)
        
        # Create temporary file (more reliable than BytesIO)
        with tempfile.NamedTemporaryFile(mode='wb', suffix='.xlsx', delete=False) as tmp:
            tmp_path = tmp.name
        
        try:
            # Write to temporary file
            with pd.ExcelWriter(tmp_path, engine='openpyxl') as writer:
                df.to_excel(writer, index=False, sheet_name='Screening Results')
                
                # Auto-adjust column widths
                worksheet = writer.sheets['Screening Results']
                for column in worksheet.columns:
                    max_length = 0
                    column_letter = column[0].column_letter
                    for cell in column:
                        try:
                            if len(str(cell.value)) > max_length:
                                max_length = len(cell.value)
                        except:
                            pass
                    adjusted_width = min(max_length + 2, 50)
                    worksheet.column_dimensions[column_letter].width = adjusted_width
            
            # Read from temporary file
            with open(tmp_path, 'rb') as f:
                excel_bytes = f.read()
            
            # Validate file size
            if len(excel_bytes) == 0:
                return None, "‚ùóÔ∏è Generated file is empty - validation failed", None
            
            # Save permanent copy
            timestamp = dtime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"screening_report_{mode}_{timestamp}.xlsx"
            filepath = os.path.join(REPORTS_DIR, filename)
            
            with open(filepath, 'wb') as f:
                f.write(excel_bytes)
            
            # Verify file was saved
            if not os.path.exists(filepath) or os.path.getsize(filepath) == 0:
                return None, "‚ùóÔ∏è Failed to save file to disk", None
            
            return excel_bytes, "‚úÖ Report generated successfully", filename
        
        finally:
            # Clean up temporary file
            try:
                os.remove(tmp_path)
            except:
                pass
    
    except Exception as e:
        return None, f"‚ùóÔ∏è Error generating report: {str(e)}", None

def get_admin_statistics():
    """Get admin statistics"""
    try:
        total_reports = len([f for f in os.listdir(REPORTS_DIR) if f.endswith(('.csv', '.xlsx'))])
        total_resumes = len([f for f in os.listdir(RESUMES_DIR)])
        
        fit_counts = {"Strongly Fit": 0, "Mid Fit": 0, "Low Fit": 0}
        
        for report_file in os.listdir(REPORTS_DIR):
            if report_file.endswith('.xlsx'):
                filepath = os.path.join(REPORTS_DIR, report_file)
                df = pd.read_excel(filepath)
                fit_counts["Strongly Fit"] += len(df[df['Fit Level'] == 'Strongly Fit'])
                fit_counts["Mid Fit"] += len(df[df['Fit Level'] == 'Mid Fit'])
                fit_counts["Low Fit"] += len(df[df['Fit Level'] == 'Low Fit'])
        
        return {
            "total_reports": total_reports,
            "total_resumes": total_resumes,
            "fit_distribution": fit_counts
        }
    
    except:
        return {"total_reports": 0, "total_resumes": 0, "fit_distribution": {}}

def show_admin_dashboard():
    """Main admin dashboard - PRESERVES YOUR ORIGINAL LOGIC + NEW FEATURES"""
    show_header_with_user()
    st.markdown("---")
    
    # Centered, large dashboard title
    st.markdown("""
        <h1 style='text-align: center; font-size: 2.5rem; font-weight: 800; margin: 2rem 0;'>
            üßëüèª‚Äçüíª Recruiter Dashboard
        </h1>
    """, unsafe_allow_html=True)
    # Tabs for clearer navigation
    tab_single, tab_bulk, tab_jd, tab_fetch, tab_stats, tab_stored = st.tabs([
        "üìù Single Screening", 
        "üìë Bulk Screening", 
        "üìÉ JD Auto-Screen", 
        "üîÑ Fetch & Screen", 
        "üìä Statistics", 
        "üìÇ Stored Resumes"
    ])

    with tab_single:
        show_single_screening()
        
    with tab_bulk:
        show_bulk_screening()
        
    with tab_jd:
        show_jd_auto_screening()
        
    with tab_fetch:
        show_fetch_and_screen_page()
        
    with tab_stats:
        # Check if function exists locally or needs import, assuming it's available since it was called previously
        if 'show_admin_statistics_page' in globals():
             show_admin_statistics_page()
        else:
             # Fallback if the function definition was missed in previous reads/imports
             st.warning("Statistics module not loaded.")
             
    with tab_stored:
        show_stored_resumes()
    
    # ==================== PREMIUM PERFORMANCE PREDICTOR ====================

def show_single_screening():
        st.markdown("""<div style="text-align: center; padding: 2rem 0;">
            <h2 style="font-size: 2.5rem; margin: 0;">üéØ AI Performance Predictor</h2>
            <p style="opacity: 0.8; font-size: 1.1rem; margin-top: 0.5rem;">Upload a resume to unlock comprehensive performance insights</p>
        </div>""", unsafe_allow_html=True)
        
        st.markdown("---")
        
        # Premium file uploader
        uploaded_resume = st.file_uploader(
            "üìÑ Upload Resume for Analysis",
            type=["pdf", "docx", "txt"],
            key="perf_pred_upload",
            help="Supported formats: PDF, DOCX, TXT"
        )
        
        if uploaded_resume:
            # Create unique hash for this file to prevent caching
            file_hash = hashlib.md5(uploaded_resume.getvalue()).hexdigest()[:8]
            
            # Check if this is a new file (different from last analyzed)
            if 'last_analyzed_hash' not in st.session_state:
                st.session_state.last_analyzed_hash = None
            if 'last_prediction_result' not in st.session_state:
                st.session_state.last_prediction_result = None
            
            # Display file info for verification
            st.info(f"üìÑ Analyzing: **{uploaded_resume.name}** ({uploaded_resume.size} bytes) - ID: {file_hash}")
            
            st.markdown("---")
            
            # Save and process resume
            with tempfile.NamedTemporaryFile(delete=False, suffix=f".{uploaded_resume.name.split('.')[-1]}") as tmp:
                uploaded_resume.seek(0)
                tmp.write(uploaded_resume.read())
                tmp_path = tmp.name
            
            try:
                with st.spinner("üîÆ Analyzing resume with advanced AI..."):
                    # Extract data
                    resume_text = extract_text_from_file(tmp_path)
                    
                    # Debug: Show extracted text length
                    text_length = len(resume_text)
                    
                    skills_list = extract_skills(resume_text)
                    years_exp = estimate_experience_years(resume_text)
                    
                    # Show extraction summary
                    with st.expander("üìä Extraction Summary", expanded=False):
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("Resume Length", f"{text_length} chars")
                        with col2:
                            st.metric("Skills Found", len(skills_list))
                        with col3:
                            st.metric("Experience", f"{years_exp} years")
                        
                        if skills_list:
                            st.write("**Skills Detected:**", ", ".join(skills_list[:10]))
                        if len(resume_text) > 100:
                            st.write("**Resume Preview:**", resume_text[:200] + "...")
                    
                    
                    # Only re-analyze if this is a different file
                    if file_hash != st.session_state.last_analyzed_hash:
                        # Predict performance with fresh data
                        prediction = predict_performance(resume_text, years_exp, skills_list)
                        st.session_state.last_prediction_result = prediction
                        st.session_state.last_analyzed_hash = file_hash
                    else:
                        # Use cached result for the same file
                        prediction = st.session_state.last_prediction_result
                    
                    st.success("‚úÖ Analysis Complete!")
                    st.markdown("")
                    
                    # ===== OVERALL SCORE DISPLAY =====
                    st.markdown("""<div class="glass-card" style="text-align: center; padding: 3rem 2rem; margin: 2rem 0;">
                        <div style="font-size: 1.2rem; opacity: 0.7; margin-bottom: 1rem;">Overall Performance Score</div>
                        <div style="position: relative; display: inline-block;">
                            <div style="font-size: 5rem; font-weight: 800; background: linear-gradient(135deg, {}, #a855f7); -webkit-background-clip: text; -webkit-text-fill-color: transparent;">{}</div>
                            <div style="font-size: 1.5rem; opacity: 0.6; margin-top: -1rem;">/ 100</div>
                        </div>
                        <div style="font-size: 1.5rem; font-weight: 600; color: {}; margin-top: 1rem;">{}</div>
                        <div style="font-size: 0.9rem; opacity: 0.6; margin-top: 0.5rem;">Confidence: {} ({}%)</div>
                    </div>""".format(
                        prediction['rating_color'],
                        int(prediction['overall_score']),
                        prediction['rating_color'],
                        prediction['rating'],
                        prediction['confidence'],
                        prediction['confidence_score']
                    ), unsafe_allow_html=True)
                    
                    # ===== 5 DIMENSION SCORES =====
                    st.markdown("### üìä Performance Breakdown")
                    
                    dims = prediction['dimension_scores']
                    dimension_data = [
                        ('Technical Excellence', dims['technical_excellence'], 'üíª'),
                        ('Professional Experience', dims['professional_experience'], 'üëî'),
                        ('Cultural & Team Fit', dims['cultural_fit'], 'ü§ù'),
                        ('Growth Trajectory', dims['growth_trajectory'], 'üìà'),
                        ('Leadership Potential', dims['leadership_potential'], 'üëë')
                    ]
                    
                    cols = st.columns(5)
                    for idx, (name, score, icon) in enumerate(dimension_data):
                        with cols[idx]:
                            color = "#22c55e" if score >= 75 else "#f59e0b" if score >= 60 else "#ef4444"
                            st.markdown(f"""<div class="glass-card" style="text-align: center; padding: 1.5rem 0.5rem;">
                                <div style="font-size: 2.5rem;">{icon}</div>
                                <div style="font-size: 2rem; font-weight: 700; color: {color}; margin: 0.5rem 0;">{int(score)}</div>
                                <div style="font-size: 0.75rem; opacity: 0.7; line-height: 1.2;">{name}</div>
                            </div>""", unsafe_allow_html=True)
                    
                    st.markdown("")
                    
                    # ===== DETAILED ANALYSIS (COLLAPSIBLE) =====
                    st.markdown("### üìã Detailed Analysis")
                    
                    # Technical Competency
                    with st.expander("üíª Technical Competency", expanded=True):
                        tech_details = prediction['dimension_details']['technical']
                        col1, col2 = st.columns(2)
                        with col1:
                            st.metric("Total Skills", tech_details['skill_count'])
                            st.metric("Future Tech Skills", tech_details['future_tech_count'])
                        with col2:
                            st.metric("Certifications", tech_details['certifications'])
                            if tech_details['depth_indicators']:
                                st.write("**Depth Indicators:**", ", ".join(tech_details['depth_indicators']))
                    
                    # Professional Experience
                    with st.expander("üëî Professional Background"):
                        exp_details = prediction['dimension_details']['experience']
                        col1, col2 = st.columns(2)
                        with col1:
                            st.metric("Years of Experience", f"{exp_details['years']} years")
                            st.metric("Senior Role", "‚úÖ Yes" if exp_details['senior_role'] else "‚ùå No")
                        with col2:
                            st.metric("Top Tier Company", "‚úÖ Yes" if exp_details['top_company'] else "‚ùå No")
                            st.metric("Achievement Metrics", exp_details['achievements'])
                    
                    # Cultural Fit
                    with st.expander("ü§ù Cultural & Team Fit"):
                        culture_details = prediction['dimension_details']['cultural_fit']
                        col1, col2 = st.columns(2)
                        with col1:
                            st.metric("Collaboration Score", f"{culture_details['collaboration_score']}/30")
                        with col2:
                            st.metric("Communication Score", f"{culture_details['communication_score']}/20")
                        st.info(f"**Team Experience:** {culture_details['team_size']}")
                    
                    # Growth Trajectory
                    with st.expander("üìà Growth & Adaptability"):
                        growth_details = prediction['dimension_details']['growth']
                        col1, col2 = st.columns(2)
                        with col1:
                            st.metric("Career Trajectory", growth_details['trajectory'])
                            st.metric("Promotions", growth_details['promotions'])
                        with col2:
                            st.metric("Learning Indicators", growth_details['learning_indicators'])
                    
                    # Leadership Potential
                    with st.expander("üëë Leadership Assessment"):
                        leadership_details = prediction['dimension_details']['leadership']
                        col1, col2 = st.columns(2)
                        with col1:
                            st.metric("Strategic Thinking", "‚úÖ Yes" if leadership_details['strategic_thinking'] else "‚ùå Limited")
                        with col2:
                            st.metric("People Management", "‚úÖ Yes" if leadership_details['people_management'] else "‚ùå Limited")
                        if leadership_details['leadership_indicators']:
                            st.write("**Leadership Keywords Found:**")
                            for indicator in leadership_details['leadership_indicators']:
                                st.write(f"‚Ä¢ {indicator}")
                    
                    # Risk Assessment
                    with st.expander("‚ö†Ô∏è Risk Analysis"):
                        risk_data = prediction['risk_assessment']
                        risk_score = risk_data['risk_score']
                        
                        if risk_score >= 80:
                            st.success(f"**Low Risk Profile** ({int(risk_score)}/100)")
                        elif risk_score >= 60:
                            st.warning(f"**Moderate Risk Profile** ({int(risk_score)}/100)")
                        else:
                            st.error(f"**High Risk Profile** ({int(risk_score)}/100)")
                        
                        if risk_data['risk_factors']:
                            st.write("**Risk Factors Identified:**")
                            for risk in risk_data['risk_factors']:
                                st.write(f"‚ö†Ô∏è {risk}")
                        else:
                            st.success("‚úÖ No significant risk factors identified")
                    
                    st.markdown("")
                    
                    # ===== AI RECOMMENDATIONS =====
                    st.markdown("### üí° AI-Powered Recommendations")
                    
                    recs = prediction['recommendations']
                    
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.markdown("""<div class="glass-card" style="padding: 1.5rem;">
                            <h4>üéØ Best Role Fit</h4>
                            <ul>
                        """, unsafe_allow_html=True)
                        for role in recs['role_fit']:
                            st.markdown(f"<li>{role}</li>", unsafe_allow_html=True)
                        st.markdown("</ul></div>", unsafe_allow_html=True)
                        
                        if recs['strengths']:
                            st.markdown("""<div class="glass-card" style="padding: 1.5rem; margin-top: 1rem;">
                                <h4>‚ú® Key Strengths</h4>
                            """, unsafe_allow_html=True)
                            for strength in recs['strengths']:
                                st.markdown(f"<div style='padding: 0.5rem 0;'>‚úÖ {strength}</div>", unsafe_allow_html=True)
                            st.markdown("</div>", unsafe_allow_html=True)
                    
                    with col2:
                        st.markdown(f"""<div class="glass-card" style="padding: 1.5rem;">
                            <h4>üë• Recommended Team Size</h4>
                            <p style="font-size: 1.2rem; font-weight: 600; margin: 1rem 0;">{recs['team_size']}</p>
                        </div>""", unsafe_allow_html=True)
                        
                        if recs['onboarding_focus']:
                            st.markdown("""<div class="glass-card" style="padding: 1.5rem; margin-top: 1rem;">
                                <h4>üöÄ Onboarding Focus Areas</h4>
                            """, unsafe_allow_html=True)
                            for focus in recs['onboarding_focus']:
                                st.markdown(f"<div style='padding: 0.5rem 0;'>üìå {focus}</div>", unsafe_allow_html=True)
                            st.markdown("</div>", unsafe_allow_html=True)
                        elif recs['development_areas']:
                            st.markdown("""<div class="glass-card" style="padding: 1.5rem; margin-top: 1rem;">
                                <h4>üìà Development Areas</h4>
                            """, unsafe_allow_html=True)
                            for area in recs['development_areas']:
                                st.markdown(f"<div style='padding: 0.5rem 0;'>üéØ {area}</div>", unsafe_allow_html=True)
                            st.markdown("</div>", unsafe_allow_html=True)
                    
                    st.markdown("")
                    
                    # ===== FINAL RECOMMENDATION =====
                    if prediction['overall_score'] >= 80:
                        rec_text = "üåü Highly Recommended - This candidate demonstrates exceptional potential across all dimensions."
                        rec_color = "#10b981"
                    elif prediction['overall_score'] >= 70:
                        rec_text = "‚≠ê Strongly Recommended - This candidate shows excellent capabilities with minor areas for development."
                        rec_color = "#22c55e"
                    elif prediction['overall_score'] >= 60:
                        rec_text = "üëç Recommended - This candidate has solid skills and good potential for growth."
                        rec_color = "#f59e0b"
                    else:
                        rec_text = "üëå Consider Carefully - This candidate may require additional evaluation or onboarding support."
                        rec_color = "#fb923c"
                    
                    st.markdown(f"""<div class="glass-card" style="padding: 2rem; border-left: 5px solid {rec_color};">
                        <h3 style="margin-top: 0; color: {rec_color};">Final Recommendation</h3>
                        <p style="font-size: 1.1rem; margin: 0;">{rec_text}</p>
                    </div>""", unsafe_allow_html=True)
                    
            except Exception as e:
                st.error(f"‚ö†Ô∏è Error analyzing resume: {str(e)}")
                import traceback
                with st.expander("See error details"):
                    st.code(traceback.format_exc())
            finally:
                # Cleanup
                if os.path.exists(tmp_path):
                    os.remove(tmp_path)
        else:
            # ===== FEATURE PREVIEW =====
            st.info("üëÜ Upload a resume above to unlock comprehensive AI-powered performance analysis")
            
            st.markdown("### ‚ú® What Makes This Analysis Special?")
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.markdown("""<div class="glass-card" style="padding: 1.5rem;">
                    <h4>üî¨ 5-Dimensional Analysis</h4>
                    <ul style="font-size: 0.9rem;">
                        <li>Technical Excellence</li>
                        <li>Professional Experience</li>
                        <li>Cultural & Team Fit</li>
                        <li>Growth Trajectory</li>
                        <li>Leadership Potential</li>
                    </ul>
                </div>""", unsafe_allow_html=True)
            
            with col2:
                st.markdown("""<div class="glass-card" style="padding: 1.5rem;">
                    <h4>üéØ AI Recommendations</h4>
                    <ul style="font-size: 0.9rem;">
                        <li>Best role fit suggestions</li>
                        <li>Ideal team size</li>
                        <li>Onboarding focus areas</li>
                        <li>Development roadmap</li>
                        <li>Risk assessment</li>
                    </ul>
                </div>""", unsafe_allow_html=True)
            
            with col3:
                st.markdown("""<div class="glass-card" style="padding: 1.5rem;">
                    <h4>üìä Advanced Insights</h4>
                    <ul style="font-size: 0.9rem;">
                        <li>Skill gap analysis</li>
                        <li>Career trajectory mapping</li>
                        <li>Confidence scoring</li>
                        <li>Risk factor identification</li>
                        <li>Comparative benchmarking</li>
                    </ul>
                </div>""", unsafe_allow_html=True)




def show_single_screening():
    """Single resume screening - YOUR ORIGINAL LOGIC + ATS"""
    st.markdown("## üìù Single Resume Screening")
    st.markdown("---")

    col1, col2 = st.columns([1.5, 1])

    with col1:
        st.subheader("¬ù Job Description")
        job_desc = st.text_area(
            "Paste job requirements:",
            height=150,
            placeholder="Python, SQL, AWS, 3+ years experience, Machine Learning...",
           
        )
    
    with col2:
        st.subheader("üìë Resume Upload")
        resume_file = st.file_uploader(
            "Upload Resume (PDF/DOCX/TXT):",
            type=['pdf', 'docx', 'txt'],
           
        )

   
    if st.button(" üöÄ Analyze Resume", type="primary", use_container_width=True):
         if not job_desc.strip():
            st.error("‚ùå Please enter job description")
         elif not resume_file:
            st.error("‚ùå Please upload a resume")
         else:
            with st.spinner("Analyzing resume..."):
                result = screen_single_resume(job_desc, resume_file)
                
                if result["status"] == "success":
                    st.success("‚úîÔ∏è Analysis complete!")
                    
                    # Main Scores Row
                    col1, col2, col3, col4 = st.columns(4)
                    
                    with col1:
                        metric_card("Skill Match", f"{result['skill_match']:.1f}%", "üí™", "#6366f1")
                    with col2:
                        metric_card("Experience Match", f"{result['exp_match']:.1f}%", "üìà", "#ec4899")
                    with col3:
                        metric_card("Overall Score", f"{result['final_score']:.1f}%", "üéØ", "#10b981")
                    with col4:
                        metric_card("ATS Score", f"{result['ats_score']:.1f}%", "ü§ñ", "#f59e0b")
                    
                    st.markdown("---")
                    
                    # ATS Details Section
                    st.subheader("ü¶æ ATS Analysis")
                    col1, col2, col3, col4, col5 = st.columns(5)
                    
                    with col1:
                        st.metric("Format", f"{result['ats_details']['format_score']}", "")
                    with col2:
                        st.metric("Keywords", f"{result['ats_details']['keyword_score']}", "")
                    with col3:
                        st.metric("Structure", f"{result['ats_details']['structure_score']}", "")
                    with col4:
                        st.metric("Content", f"{result['ats_details']['content_score']}", "")
                    with col5:
                        st.metric("ATS Rating", result['ats_rating'], "")
                    
                    # ATS Issues
                    if result['ats_details']['issues']:
                        st.subheader("‚Äº¬è ATS Issues Found")
                        for issue in result['ats_details']['issues']:
                            st.write(issue)
                    else:
                        st.success("‚òëÔ∏è No ATS issues found!")
                    
                    st.markdown("---")
                    
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.subheader("‚úÖ Matched Skills")
                        analysis = result['analysis']
                        matched = analysis.get("matched_skills", [])
                        if matched:
                            for skill in matched[:10]:
                                st.write(f"‚ö™Ô∏è {skill}")
                        else:
                            st.info("No skills matched")
                    
                    with col2:
                        st.subheader("‚ùå Missing Skills")
                        missing = analysis.get("missing_skills", [])
                        if missing:
                            for skill in missing[:10]:
                                st.write(f"üî¥ {skill}")
                        else:
                            st.success("All required skills present!")
                    
                    st.markdown("---")
                    
                    st.subheader("üìä Summary")
                    st.write(analysis.get("summary", "No summary"))
                    
                    
                    st.markdown("---")
                    
                    # Download Resume Button - Original Format
                    resume_file.seek(0)  # Reset file pointer
                    file_bytes = resume_file.read()
                    file_extension = resume_file.name.split('.')[-1].lower()
                    
                    # Set proper MIME type based on file extension
                    mime_types = {
                        'pdf': 'application/pdf',
                        'docx': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document',
                        'txt': 'text/plain'
                    }
                    mime_type = mime_types.get(file_extension, 'application/octet-stream')
                    
                    st.download_button(
                        "üì• Download Resume",
                        data=file_bytes,
                        file_name=resume_file.name,
                        mime=mime_type,
                        use_container_width=True
                    )
                
                else:
                    st.error(f"‚ö†Ô∏è Error: {result['message']}")

def show_bulk_screening():
    """Bulk resume screening (fixed: persistent uploads + stable report generation)"""
    st.markdown("## üìë Bulk Resume Screening")
    st.markdown("---")

    # Ensure session state keys exist
    if "bulk_uploaded_files" not in st.session_state:
        st.session_state.bulk_uploaded_files = []  # list of dicts: {"name":..., "content": bytes}
    if "bulk_results" not in st.session_state:
        st.session_state.bulk_results = None
    if "bulk_jd_text" not in st.session_state:
        st.session_state.bulk_jd_text = ""

    col1, col2 = st.columns([1.5, 1])

    # LEFT: Job description (persisted)
    with col1:
        st.subheader("üìù¬ù Job Description")
        # use session state to persist JD between reruns
        jd = st.text_area(
            "Paste job requirements:",
            height=150,
            placeholder="Python, SQL, AWS, 3+ years experience...",
            key="bulk_jd"
        )
        # keep a copy in a simple session var for use outside widget checks
        st.session_state.bulk_jd_text = jd

    # RIGHT: Uploader (upload adds to session state list)
    with col2:
        st.subheader("üìë Upload Resumes")
        uploaded = st.file_uploader(
            "Upload multiple resumes (PDF/DOCX/TXT):",
            type=['pdf', 'docx', 'txt'],
            accept_multiple_files=True,
            key="bulk_uploader_widget"
        )

        # If new files are uploaded via the widget, store their bytes+name into session state
        if uploaded:
            # maintain uniqueness by filename+size to avoid duplicates in session list
            existing_keys = {f"{f['name']}|{len(f['content'])}" for f in st.session_state.bulk_uploaded_files}
            added = 0
            for up in uploaded:
                try:
                    up_bytes = up.read()
                    key = f"{up.name}|{len(up_bytes)}"
                    if key not in existing_keys:
                        st.session_state.bulk_uploaded_files.append({"name": up.name, "content": up_bytes})
                        existing_keys.add(key)
                        added += 1
                except Exception as e:
                    st.warning(f"Failed to read {up.name}: {e}")
            if added:
                st.success(f"Added {added} file(s) to upload list (stored in session).")

       
        else:
            st.info("No files uploaded yet. Use the uploader above to add resumes (they will persist).")

    st.markdown("---")

    # Action buttons: Screen and (separately) Generate Report
    actions_col1, actions_col2, actions_col3 = st.columns([1, 1, 1])

    with actions_col1:
        if st.button("üöÄ Screen All Resumes", type="primary", use_container_width=True):
            job_desc = st.session_state.bulk_jd_text or ""
            if not job_desc.strip():
                st.error("‚ùå Please enter job description before screening")
            elif not st.session_state.bulk_uploaded_files:
                st.error("‚ùå Please upload resumes before screening")
            else:
                # Recreate file-like objects for screen_bulk_resumes
                from io import BytesIO
                temp_files = []
                for f in st.session_state.bulk_uploaded_files:
                    bio = BytesIO(f["content"])
                    bio.name = f["name"]
                    bio.seek(0)
                    temp_files.append(bio)

                with st.spinner(f"Screening {len(temp_files)} resumes..."):
                    try:
                        results = screen_bulk_resumes(job_desc, temp_files)
                        # save results in session state for later report generation/download
                        st.session_state.bulk_results = results
                        st.success(f"‚úÖ Screened {len(results)} resumes!")
                    except Exception as e:
                        st.error(f"‚ö†Ô∏è Error during screening: {e}")

    # Show summary + table if results exist in session
    if st.session_state.bulk_results:
        results = st.session_state.bulk_results

        st.markdown("---")
        colA, colB, colC, colD = st.columns(4)
        with colA:
            st.metric("Total Resumes", len(results))
        with colB:
            st.metric("Strongly Fit", len([r for r in results if r["fit"] == "Strongly Fit"]))
        with colC:
            st.metric("Mid Fit", len([r for r in results if r["fit"] == "Mid Fit"]))
        with colD:
            st.metric("Low Fit", len([r for r in results if r["fit"] == "Low Fit"]))

        st.markdown("---")
        st.subheader("ü•áü•àü•â Top 3 Candidates")
        top_3 = results[:3]
        for idx, candidate in enumerate(top_3, 1):
            with st.container():
                c1, c2, c3, c4, c5 = st.columns([2, 2, 2, 2, 1])
                with c1:
                    st.write(f"**#{idx} {candidate['candidate_name']}**")
                with c2:
                    st.write(f"üìß {candidate['email']}")
                with c3:
                    st.write(f"üìû {candidate['contact']}")
                with c4:
                    st.write(f"**Score: {candidate['overall_score']}%** | **ATS: {candidate['ats_score']}%** ({candidate['fit']})")
                with c5:
                    if candidate.get('file_content'):
                        st.download_button(
                            "‚¨áÔ∏è ",
                            candidate['file_content'],
                            file_name=candidate['original_filename'],
                            key=f"download_top_{idx}"
                        )
            st.divider()

        st.markdown("---")
        st.subheader("üì∂ All Ranking Results")
        df = pd.DataFrame(results)
        display_df = df[["candidate_name", "email", "contact", "experience_level", "skill_match", "exp_match", "overall_score", "ats_score", "fit"]].copy()
        display_df.insert(0, "Rank", range(1, len(display_df) + 1))
        display_df = display_df.rename(columns={
            "candidate_name": "Candidate",
            "email": "Email",
            "contact": "Contact",
            "experience_level": "Experience",
            "skill_match": "Skill %",
            "exp_match": "Exp %",
            "overall_score": "Overall Score",
            "ats_score": "ATS Score",
            "fit": "Fit Level"
        })
        # Use st.table for proper HTML rendering and text visibility
        st.table(display_df)


        # Pie chart for fit distribution (safe fallback if no results)
        try:
            fit_counts = pd.Series({
                "Strongly Fit": len([r for r in results if r["fit"] == "Strongly Fit"]),
                "Mid Fit": len([r for r in results if r["fit"] == "Mid Fit"]),
                "Low Fit": len([r for r in results if r["fit"] == "Low Fit"])
            })
            fig = px.pie(
                values=fit_counts.values,
                names=fit_counts.index,
                title="Candidate Fit Distribution",
            )
            st.plotly_chart(fig, use_container_width=True)
        except Exception:
            pass

        st.markdown("---")

        # GENERATE / DOWNLOAD REPORT: this is separate from the screening button
        gen_col1, gen_col2 = st.columns([1, 1])

        with gen_col1:
            if st.button("üìÑ Generate Excel Report", key="bulk_save_btn", use_container_width=True):
                try:
                    excel_bytes, message, filename = save_bulk_report(results, st.session_state.bulk_jd_text or "", "bulk")
                    if excel_bytes:
                        # store for download
                        st.session_state.bulk_download_data = excel_bytes
                        st.session_state.bulk_download_filename = filename
                        st.success(message)
                    else:
                        st.error(message)
                except Exception as e:
                    st.error(f"√¢¬ù≈í Error creating report: {e}")

        with gen_col2:
            if st.session_state.get("bulk_download_data"):
                st.download_button(
                    "‚¨áÔ∏è Download Excel Report",
                    st.session_state.bulk_download_data,
                    file_name=st.session_state.bulk_download_filename or "screening_report.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    key="bulk_report_download",
                    use_container_width=True
                )
    else:
        st.info("No screening results yet. Click **Screen All Resumes** to start.")


def show_jd_auto_screening():
    """JD-Driven auto screening"""
    st.markdown("## üìÉ JD-Driven Auto Screening")
    st.info("üîÑ Automatically screens all resumes in a folder against the JD")
    st.markdown("---")

    # ---------------------------
    # Session state initialization
    # ---------------------------
    if "auto_results" not in st.session_state:
        st.session_state.auto_results = None
    if "auto_download_data" not in st.session_state:
        st.session_state.auto_download_data = None
    if "auto_download_filename" not in st.session_state:
        st.session_state.auto_download_filename = None

    col1, col2 = st.columns([1.5, 1])

    with col1:
        st.subheader("üìù¬ù Job Description")
        job_desc = st.text_area(
            "Paste job requirements:",
            height=150,
            placeholder="Python, SQL, AWS, 3+ years experience...",
            key="auto_jd"
        )

    with col2:
        st.subheader("üóÇÔ∏è¬Å Folder Path")
        folder_path = st.text_input(
            "Enter folder path with resumes:",
            placeholder="/path/to/resumes/folder"
        )

    # ---------------------------
    # Auto-screen button
    # ---------------------------
    if st.button("üöÄ Auto-Screen Folder", type="primary", use_container_width=True):
        if not job_desc.strip():
            st.error("‚ùå Please enter job description")
            return

        if not folder_path.strip():
            st.error("‚ùå Please enter folder path")
            return

        with st.spinner("Auto-screening resumes..."):
            response = screen_with_jd(job_desc, folder_path)

        if response["status"] != "success":
            st.error(f"‚ö†Ô∏è Error: {response['message']}")
            return

        # Save results to session state
        st.session_state.auto_results = response["results"]
        st.session_state.auto_download_data = None   # Clear previous download
        st.session_state.auto_download_filename = None

        st.success(f"‚úÖ Auto-screened {len(st.session_state.auto_results)} resumes!")

    # ------------------------------------------------
    # SHOW RESULTS ONLY IF AUTO-SCREENING WAS COMPLETED
    # ------------------------------------------------
    if st.session_state.auto_results:
        results = st.session_state.auto_results

        col1, col2, col3, col4 = st.columns(4)

        with col1:
            st.metric("Total Resumes", len(results))
        with col2:
            st.metric("Strongly Fit", len([r for r in results if r["fit"] == "Strongly Fit"]))
        with col3:
            st.metric("Mid Fit", len([r for r in results if r["fit"] == "Mid Fit"]))
        with col4:
            st.metric("Low Fit", len([r for r in results if r["fit"] == "Low Fit"]))

        st.markdown("---")

        # ---------------------------
        # Top 3 candidates section
        # ---------------------------
        st.subheader("ü•áü•àü•â Top 3 Candidates")
        top_3 = results[:3]

        for idx, candidate in enumerate(top_3, 1):
            with st.container():
                c1, c2, c3, c4, c5 = st.columns([2, 2, 2, 2, 1])

                with c1:
                    st.write(f"**#{idx} {candidate['candidate_name']}**")
                with c2:
                    st.write(f"üìß {candidate['email']}")
                with c3:
                    st.write(f"üìû {candidate['contact']}")
                with c4:
                    st.write(
                        f"**Score: {candidate['overall_score']}%** | "
                        f"**ATS: {candidate['ats_score']}%** ({candidate['fit']})"
                    )
                with c5:
                    if candidate.get("file_content"):
                        st.download_button(
                            "‚¨áÔ∏è",
                            candidate["file_content"],
                            file_name=candidate["original_filename"],
                            key=f"auto_download_{idx}"
                        )

            st.divider()

        st.markdown("---")

        # ---------------------------
        # Full Data Table
        # ---------------------------
        st.subheader("üë§ All Candidates")

        df = pd.DataFrame(results)
        display_df = df[[
            "candidate_name", "email", "contact", 
            "experience_level", "skill_match", "exp_match",
            "overall_score", "ats_score", "fit"
        ]].copy()

        display_df.insert(0, "Rank", range(1, len(display_df) + 1))
        display_df = display_df.rename(columns={
            "candidate_name": "Candidate",
            "email": "Email",
            "contact": "Contact",
            "experience_level": "Experience",
            "skill_match": "Skill %",
            "exp_match": "Exp %",
            "overall_score": "Overall Score",
            "ats_score": "ATS Score",
            "fit": "Fit Level"
        })

        # Use st.table for proper HTML rendering and text visibility
        st.table(display_df)


        st.markdown("---")

        # ---------------------------
        # Report generator
        # ---------------------------
        c1, c2 = st.columns([1, 1])

        with c1:
            if st.button("üìÉ Generate Excel Report", key="auto_save_btn", use_container_width=True):
                excel_bytes, message, filename = save_bulk_report(results, job_desc, "auto")

                if excel_bytes:
                    st.session_state.auto_download_data = excel_bytes
                    st.session_state.auto_download_filename = filename
                    st.success(message)
                else:
                    st.error(message)

        with c2:
            if st.session_state.auto_download_data:
                st.download_button(
                    "‚¨áÔ∏è Download Excel Report",
                    st.session_state.auto_download_data,
                    file_name=st.session_state.auto_download_filename,
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    key="auto_report_download",
                    use_container_width=True
                )

STATS_PATH = "stats.json"  # same file you are already using

def reset_admin_statistics():
    if os.path.exists(STATS_PATH):
        os.remove(STATS_PATH)

    # 2) Delete all generated reports (this is what total reports counts)
    if os.path.exists(REPORTS_DIR):
        for f in os.listdir(REPORTS_DIR):
            if f.lower().endswith((".csv", ".xlsx")):
                try:
                    os.remove(os.path.join(REPORTS_DIR, f))
                except Exception:
                    pass

    # 3) Optionally also clear stored resumes if you want Total Resumes to go to 0
    if os.path.exists(RESUMES_DIR):
        for f in os.listdir(RESUMES_DIR):
            if f.lower().endswith((".pdf", ".docx", ".txt")):
                try:
                    os.remove(os.path.join(RESUMES_DIR, f))
                except Exception:
                    pass

    # 4) Clear cached results in memory
    for key in [
        "bulkresults",
        "autoresults",
        "bulkdownloaddata",
        "autodownloaddata",
        "bulkdownloadfilename",
        "autodownloadfilename",
    ]:
        if key in st.session_state:
            del st.session_state[key]

def show_admin_statistics_page():
    """Show admin statistics"""
    st.markdown("## üìàüìâ Statistics & Analytics")
    st.markdown("---")
    
    stats = get_admin_statistics()
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        metric_card("Total Reports", stats.get("total_reports", 0), "üìë", "#6366f1")
    with col2:
        metric_card("Total Resumes Stored", stats.get("total_resumes", 0), "üóÇÔ∏è", "#ec4899")
    with col3:
        metric_card("Total Screened", sum(stats.get("fit_distribution", {}).values()), "üîÑ", "#10b981")
    
    st.markdown("---")
    with st.expander("Reset statistics", expanded=False):
        st.info("This will clear counters and cached statistics. It will not delete stored reports or resumes.")
        confirm = st.checkbox("I understand and want to reset all statistics")
        if st.button("Reset statistics now", type="primary", use_container_width=True, disabled=not confirm):
            reset_admin_statistics()
            st.success("Statistics have been reset.")
            st.rerun()
    fit_dist = stats.get("fit_distribution", {})
    
    if fit_dist and any(fit_dist.values()):
        fig = px.pie(
            values=fit_dist.values(),
            names=fit_dist.keys(),
            title="Overall Candidate Fit Distribution",
            color_discrete_map={
                "Strongly Fit": "#10b981",
                "Mid Fit": "#f59e0b",
                "Low Fit": "#ef4444"
            }
        )
        
        st.plotly_chart(fig, use_container_width=True)
    
    else:
        st.info(" No screening data available yet")

def show_stored_resumes():
    """Show stored resumes"""
    st.markdown("## üìÅ¬Å Stored Resumes")
    st.markdown("---")
    st.info("Resumes are only saved when you manually click **Save Report**. No automatic saving.")

    if not os.path.exists(RESUMES_DIR):
        st.warning("Resumes directory not found.")
        return

    resumes = [f for f in os.listdir(RESUMES_DIR) if f.lower().endswith((".pdf", ".docx", ".txt"))]

    if not resumes:
        st.info("No resumes stored yet.")
        return

    st.success(f"Found {len(resumes)} stored resumes")

    for idx, resume in enumerate(resumes):
        filepath = os.path.join(RESUMES_DIR, resume)
        col1, col2, col3 = st.columns([4, 2, 2])

        with col1:
            st.write(resume)

        with col2:
            with open(filepath, "rb") as f:
                st.download_button(
                    "Download",
                    f,
                    file_name=resume,
                    key=f"stored_download_{idx}",
                    use_container_width=True,
                )

        with col3:
            if st.button("Delete", key=f"stored_delete_{idx}", use_container_width=True):
                try:
                    os.remove(filepath)
                    st.success(f"Deleted {resume}")
                    st.experimental_rerun()
                except Exception as e:
                    st.error(f"Error deleting {resume}: {e}")

    

